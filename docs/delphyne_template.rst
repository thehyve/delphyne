Getting started with delphyne
=============================

.. contents::
    :local:
    :backlinks: none


delphyne is intended to be used with **delphyne-template**,
an ETL template for converting source data to the OMOP CDM.

delphyne-template complements delphyne's functionality by providing a project structure
that satisfies delphyne's assumptions regarding folders and scripts locations,
greatly simplifying the setup process. It also ensures the optimal use of the package
by providing a basic wrapper implementation, a customizable target CDM model, and sample configuration files
for database connection and source data loading, among other features.

Project setup
-------------

To get started, simply go to `delphyne-template on GitHub <https://github.com/thehyve/delphyne-template>`_,
and click on the "Use this template" button to create a new repository for your project.

Clone the project to a local environment where a delphyne-compatible Python version is available
(see :ref:`index:Requirements`), and install the dependencies:

.. code-block:: bash

   pip install -r requirements.txt

delphyne itself will be automatically installed as one of the dependencies.

Project structure
^^^^^^^^^^^^^^^^^

A project built on delphyne-template will be structured as follows:

::

    project_root/
    ├── config/
    ├── docs/
    ├── resources/
    │   ├── mapping_tables/
    │   ├── synthetic_data/
    │   └── vocabularies/
    │       ├── custom/
    │       ├── source_to_concept_map/
    │       └── standard/
    ├── src/
    │   ├── main/
    │   │   ├── python/
    │   │   │   ├── cdm/
    │   │   │   ├── transformation/
    │   │   │   ├── util/
    │   │   │   └── wrapper.py
    │   │   └── sql/
    │   └── test/
    └── main.py

The folders listed below are **required by delphyne** and should not be renamed or removed:

- **config**:
  configuration files for general ETL setup, source data, and logging;
- **resources/vocabularies**:
  expected location for standard OMOP vocabulary files, custom vocabularies, and source to concept mappings;
- **src**:
  ETL code and tests.

The following folders are provided for convenience and can be safely removed:

- **docs**:
  this is the place where you would typically place any ETL documentation,
  e.g. the mapping specifications markdown generated by `Rabbit in a Hat <http://ohdsi.github.io/WhiteRabbit/RabbitInAHat.html>`_;
- **resources/mapping_tables**:
  any mapping files, other than source to concept mappings;
- **resources/synthetic_data**:
  any synthetic data used in the ETL development,
  e.g. generated using `White Rabbit <http://ohdsi.github.io/WhiteRabbit/WhiteRabbit.html>`_.

Running the ETL
---------------

All you need is to specify the path to a custom configuration file (see step 1 of `ETL configuration`_):

.. code-block:: bash

   python main.py -c <path_to_config.yml>

A log of the ETL run will be written to ``logs/<timestamp><version>.log``.

Building the ETL
----------------

The core of the ETL is the module ``wrapper.py`` (under ``src/main/python``),
which defines a subclass of delphyne's :class:`.Wrapper` responsible for controlling the execution flow.
You can specify which operations to execute in which order by editing the content of the ``Wrapper.run()`` method.

By default, the method begins with the following calls:

- :meth:`~.Wrapper.create_schemas()`
- :meth:`~.Wrapper.drop_cdm()`
- :meth:`~.Wrapper.create_cdm()`

These commands automatically create the target schemas and CDM tables (unless already present),
and drop existing converted data, providing a clean database at the start of each ETL iteration.
Note that vocabulary tables will be automatically created but not dropped.

Additionally, :meth:`~.Wrapper.summarize()` is called at the end of the ETL run
to produce an overview of data sources and transformations (failed and successful).

Please leave the order of these operations unchanged.

.. note::
   Throughout this documentation, when giving instructions to edit the "Wrapper's run method",
   we always refer to the Wrapper implementation in delphyne-template, not delphyne's original Wrapper class.

Pre-ETL steps
^^^^^^^^^^^^^

Source data can be read from file (see :ref:`index:Supported file formats`) or database (see :ref:`index:Supported DBMSs`);
in the latter case, it is your responsibility to load the data to the database before commencing the ETL process,
as delphyne and delphyne-template cannot currently assist you with this.

ETL configuration
^^^^^^^^^^^^^^^^^

A full description of the configuration options is available in the `configuration section <TODO>`_.
It is recommended to keep all configuration files inside the ``config`` folder:
files at this location, except for the provided samples, will be automatically ignored by git,
so that any confidential information is not accidentally shared.

**1. General ETL configuration**

     Copy and rename ``config-sample.yml`` to any desired file name;
     you can have as many configuration files as needed for different ETL execution scenarios.

     Make sure to fill in the ``database`` and ``schema_translate_map`` sections.
     If available, also specify the location of the (synthetic) source data (``source_data_folder`` section);
     this can be anywhere inside or outside the repository.
     Other configuration options can be left to their default values.

**2. Source data configuration** (optional)

     You only need to perform this step if you are reading source data from file.

     Copy and rename ``source_config-sample.yml`` to ``source-config.yml``.
     The configuration allows you to specify the correct delimiters and data types for individual source data files.

**3. Logging configuration**

     Copy and rename ``logging-sample.yml`` to ``logging.yml``.
     By default, logging will be provided at the INFO level.

ETL setup
^^^^^^^^^

**4. Customize the target CDM model**

     Follow the instructions in XXX to create a custom CDM model for your ETL.

**5. Load the standard vocabularies**

     Follow the instructions in XXX to obtain the standard OMOP vocabularies required by your project and load them to the database.
     You can repeat the procedure at any stage of ETL development (provided you first drop the vocabulary schema manually).

ETL development
^^^^^^^^^^^^^^^

The following steps can be executed in any desired order.

Should you need more information to troubleshoot errors, specify a different logging level in ``logging.yml``
(see the `configuration section <TODO>`_ for more information).

**6. Writing the transformation scripts**

     Transformations from source data to the target CDM can be implemented in one of several different styles;
     the specific choice depends

6.1. General structure

     (python / sql) - any general purpose function can be added to util/

6.2. Obtaining the source data

     See :ref:`index:Supported DBMSs`.




   Specify the execution order of transformations in the wrapper run() method

**7. Write tests for the transformations**

   python / R

Further development options:

**8. Load custom vocabularies (optional)**

**10. Load source to concept mappings (optional)**

ETL info
^^^^^^^^
- Replace the generic ``README.md`` with a project-specific version of ``README-sample.md``
- Make sure to regularly update your ETL version in ``main.py`` (``__version__`` is initially set to ``0.1.0``)
