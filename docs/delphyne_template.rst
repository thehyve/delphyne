Getting started with delphyne
=============================

.. contents::
    :local:
    :backlinks: none


delphyne is intended to be used with **delphyne-template**,
an ETL template for converting source data to the OMOP CDM.

delphyne-template complements delphyne's functionality by providing a project structure
that satisfies delphyne's assumptions regarding folders and scripts locations,
greatly simplifying the setup process. It also ensures the optimal use of the package
by providing a basic wrapper implementation, a customizable target CDM model, and sample configuration files
for database connection and source data loading, among other features.

Project setup
-------------

To get started, simply go to `delphyne-template on GitHub <https://github.com/thehyve/delphyne-template>`_,
and click on the "Use this template" button to create a new repository for your project.

Clone the project to a local environment where a delphyne-compatible Python version is available
(see :ref:`index:Requirements`), and install the dependencies:

.. code-block:: bash

   pip install -r requirements.txt

delphyne itself will be automatically installed as one of the dependencies.

Project structure
^^^^^^^^^^^^^^^^^

A project built on delphyne-template will be structured as follows:

::

    project_root/
    ├── config/
    ├── docs/
    ├── resources/
    │   ├── mapping_tables/
    │   ├── synthetic_data/
    │   └── vocabularies/
    │       ├── custom/
    │       ├── source_to_concept_map/
    │       └── standard/
    ├── src/
    │   ├── main/
    │   │   ├── python/
    │   │   │   ├── cdm/
    │   │   │   ├── transformation/
    │   │   │   ├── util/
    │   │   │   └── wrapper.py
    │   │   └── sql/
    │   └── test/
    ├── main.py
    ├── README.md
    └── requirements.txt

The folders listed below are **required by delphyne** and should not be renamed or removed:

- **config**:
  configuration files for general ETL setup, source data, and logging;
- **resources/vocabularies**:
  expected location for standard OMOP vocabulary files, custom vocabularies, and source to concept mappings;
- **src**:
  ETL code and tests.

The following folders are provided for convenience and can be safely removed:

- **docs**:
  this is the place where you would typically place any ETL documentation,
  e.g. the mapping specifications markdown generated by `Rabbit in a Hat <http://ohdsi.github.io/WhiteRabbit/RabbitInAHat.html>`_;
- **resources/mapping_tables**:
  any mapping files, other than source to concept mappings;
- **resources/synthetic_data**:
  any synthetic data used in the ETL development,
  e.g. generated using `White Rabbit <http://ohdsi.github.io/WhiteRabbit/WhiteRabbit.html>`_.

Running the ETL
---------------

All you need is to specify the path to a custom configuration file (see step 1 of `ETL configuration`_):

.. code-block:: bash

   python main.py -c <path_to_config.yml>

A log of the ETL run will be written to ``logs/<timestamp><version>.log``.

Building the ETL
----------------

The core of the ETL is the module ``wrapper.py`` (under ``src/main/python``),
which defines a subclass of delphyne's :class:`.Wrapper` responsible for controlling the execution flow.
You can specify which operations to execute in which order by editing the content of the ``Wrapper.run()`` method.

By default, the method begins with the following calls:

- :meth:`~.Wrapper.create_schemas()`
- :meth:`~.Wrapper.drop_cdm()`
- :meth:`~.Wrapper.create_cdm()`

These commands automatically create the target schemas and CDM tables (unless already present),
and drop existing converted data, providing a clean database at the start of each ETL iteration.
Note that vocabulary tables will be automatically created but not dropped.

Additionally, :meth:`~.Wrapper.summarize()` is called at the end of the ETL run
to produce an overview of data sources and transformations (failed and successful).

Please leave the order of these operations unchanged.

.. note::
   Throughout this documentation, when giving instructions to edit the "Wrapper's run method",
   we always refer to the Wrapper implementation in delphyne-template, not delphyne's original Wrapper class.

Pre-ETL steps
^^^^^^^^^^^^^

Source data can be read from file (see :ref:`index:Supported file formats`) or database (see :ref:`index:Supported DBMSs`);
in the latter case, it is your responsibility to load the data to the database before commencing the ETL process,
as delphyne and delphyne-template cannot currently assist you with this.

ETL configuration
^^^^^^^^^^^^^^^^^

A full description of the configuration options is available in the `configuration section <TODO>`_.
It is recommended to keep all configuration files inside the ``config`` folder:
files at this location, except for the provided samples, will be automatically ignored by git,
so that any confidential information is not accidentally shared.

**1. Configure the general ETL execution**

Copy and rename ``config-sample.yml`` to any desired file name;
you can have as many configuration files as needed for different ETL execution scenarios.

Make sure to fill in the ``database`` and ``schema_translate_map`` sections.
If available, also specify the location of the (synthetic) source data (``source_data_folder`` section);
this can be anywhere inside or outside the repository.
Other configuration options can be left to their default values for the moment.

**2. Configure source data** (optional)

You only need to perform this step if you are reading source data from file.

Copy and rename ``source_config-sample.yml`` to ``source-config.yml``.
The configuration allows you to specify the correct delimiters and data types for individual source data files.

**3. Configure logging**

Copy and rename ``logging-sample.yml`` to ``logging.yml``.
By default, logging will be provided at the INFO level.

ETL setup
^^^^^^^^^

**4. Customize the target CDM model**

Follow the instructions in :ref:`cdm:Defining the CDM` to define a (custom) CDM model for your ETL.
Available out-of-the-box CDM versions are listed in :ref:`index:Supported CDM versions`.

All standard vocabulary tables, and source to concept map tables (see :ref:`stcm:Source to concept map`),
are associate by default to the "vocabulary" schema, while other tables (including custom ones)
can be associated to the "cdm" or other schemas (the exact names are defined in the general configuration's
``schema_translate_map`` option, see `configuration section <TODO>`_).

We recommend to not mix up this basic schema subdivision.

**5. Load the standard OMOP vocabularies**

Follow the instructions in :ref:`standard_vocab:Standard vocabularies` to obtain the standard OMOP vocabularies
required by your project and load them to the database.
This is an expensive operation that should be repeated as few times as possible.

**6. Load custom vocabularies** (optional)

See instructions in :ref:`custom_vocab:Custom vocabularies`.

ETL development
^^^^^^^^^^^^^^^

Should you need more information to troubleshoot errors, specify a more informative logging level in ``logging.yml``
(see the `configuration section <TODO>`_).

**7. Write source data transformations**

Create your transformation scripts inside ``transformation/`` (for Python) or ``sql/`` (for SQL) folder,
then add them to the Wrapper's run method to have them executed during an ETL run.

Transformations from source data to the target CDM can be implemented in one of several different styles;
see :ref:`transformations:Transformations`.

**7.1. Write transformations in Python**

- General structure (imports etc)
- To extract source data inside a transformation, see :ref:`source_data:Source data`
- To map values from the source data to standard OMOP concept_ids, see :ref:`semantic_mapping:Semantic mapping tools`
- You can place any helper functions required by multiple Python transformations in the ``util/`` folder

**7.2. Write transformations in SQL**

TBD

**8. Write tests for the transformations**

**8.1. Write tests in Python**

(not yet supported)

**8.2. Write tests in R**

``/src/test/R`` contains a test framework that can be automatically generated by Rabbit in a Hat.
See `readme.md` in the folder for details on how to build and use the framework.

ETL info
^^^^^^^^
- Edit ``README.md`` with project-specific information
- Make sure to regularly update your ETL version in ``main.py`` (``__version__`` is initially set to ``0.1.0``)
